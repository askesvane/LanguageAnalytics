{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system tools\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(\"..\"))\n",
    "\n",
    "# data munging tools\n",
    "import pandas as pd\n",
    "import classifier_utils as clf\n",
    "\n",
    "# Machine learning stuff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_test = os.path.join(\"data\", \"Corona_test.csv\")\n",
    "\n",
    "DATA1 = pd.read_csv(filename_test, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_train = os.path.join(\"data\", \"Corona_train.csv\")\n",
    "\n",
    "DATA2 = pd.read_csv(filename_train, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the 2 df's\n",
    "DATA = pd.concat([DATA1, DATA2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44955, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UserName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7664</th>\n",
       "      <td>52616</td>\n",
       "      <td>??????</td>\n",
       "      <td>18/03/2020</td>\n",
       "      <td>God spread small flu called #CoronavirusOutbre...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41562</th>\n",
       "      <td>86514</td>\n",
       "      <td>Queensland, Australia</td>\n",
       "      <td>11/04/2020</td>\n",
       "      <td>Food delivery giants are resisting calls to cu...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7535</th>\n",
       "      <td>52487</td>\n",
       "      <td>Edmonton</td>\n",
       "      <td>18/03/2020</td>\n",
       "      <td>#storeclerks\\r\\r\\n#coronavirus \\r\\r\\n#COVID19 ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11253</th>\n",
       "      <td>56205</td>\n",
       "      <td>UK</td>\n",
       "      <td>19/03/2020</td>\n",
       "      <td>@FootyNutty442 @JacJac66 They should be stayin...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8086</th>\n",
       "      <td>53038</td>\n",
       "      <td>Across Missouri</td>\n",
       "      <td>18/03/2020</td>\n",
       "      <td>If you are a business owner, you are probably ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40597</th>\n",
       "      <td>85549</td>\n",
       "      <td>Florida, USA</td>\n",
       "      <td>10/04/2020</td>\n",
       "      <td>A Consumer Psychologist Details What Businesse...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19640</th>\n",
       "      <td>64592</td>\n",
       "      <td>Australia</td>\n",
       "      <td>22/03/2020</td>\n",
       "      <td>#KathandKim predicted #toiletpaperpanic back i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28636</th>\n",
       "      <td>73588</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>27/03/2020</td>\n",
       "      <td>#Work #Labor #Pandemic #Coronavirus #COVID?19 ...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21485</th>\n",
       "      <td>66437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23/03/2020</td>\n",
       "      <td>@NBDR_CEO  omg I just broke out in laughter ov...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43148</th>\n",
       "      <td>88100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/04/2020</td>\n",
       "      <td>@CNN In addition to the shortage of medical an...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ScreenName               Location     TweetAt  \\\n",
       "UserName                                                  \n",
       "7664           52616                 ??????  18/03/2020   \n",
       "41562          86514  Queensland, Australia  11/04/2020   \n",
       "7535           52487               Edmonton  18/03/2020   \n",
       "11253          56205                     UK  19/03/2020   \n",
       "8086           53038        Across Missouri  18/03/2020   \n",
       "40597          85549           Florida, USA  10/04/2020   \n",
       "19640          64592              Australia  22/03/2020   \n",
       "28636          73588        Los Angeles, CA  27/03/2020   \n",
       "21485          66437                    NaN  23/03/2020   \n",
       "43148          88100                    NaN  12/04/2020   \n",
       "\n",
       "                                              OriginalTweet  \\\n",
       "UserName                                                      \n",
       "7664      God spread small flu called #CoronavirusOutbre...   \n",
       "41562     Food delivery giants are resisting calls to cu...   \n",
       "7535      #storeclerks\\r\\r\\n#coronavirus \\r\\r\\n#COVID19 ...   \n",
       "11253     @FootyNutty442 @JacJac66 They should be stayin...   \n",
       "8086      If you are a business owner, you are probably ...   \n",
       "40597     A Consumer Psychologist Details What Businesse...   \n",
       "19640     #KathandKim predicted #toiletpaperpanic back i...   \n",
       "28636     #Work #Labor #Pandemic #Coronavirus #COVID?19 ...   \n",
       "21485     @NBDR_CEO  omg I just broke out in laughter ov...   \n",
       "43148     @CNN In addition to the shortage of medical an...   \n",
       "\n",
       "                   Sentiment  \n",
       "UserName                      \n",
       "7664      Extremely Negative  \n",
       "41562               Negative  \n",
       "7535                Positive  \n",
       "11253               Positive  \n",
       "8086                Negative  \n",
       "40597                Neutral  \n",
       "19640                Neutral  \n",
       "28636     Extremely Positive  \n",
       "21485     Extremely Positive  \n",
       "43148               Positive  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA2.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number in each sentiment category "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive              12369\n",
       "Negative              10958\n",
       "Neutral                8332\n",
       "Extremely Positive     7223\n",
       "Extremely Negative     6073\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance(dataframe, n=500):\n",
    "    \"\"\"\n",
    "    Create a balanced sample from imbalanced datasets.\n",
    "    \n",
    "    dataframe: \n",
    "        Pandas dataframe with a column called 'text' and one called 'label'\n",
    "    n:         \n",
    "        Number of samples from each Sentiment, defaults to 500\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use pandas select a random bunch of examples from each label\n",
    "    out = (dataframe.groupby('Sentiment', as_index=False)\n",
    "            .apply(lambda x: x.sample(n=n))\n",
    "            .reset_index(drop=True))\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_balanced = balance(DATA, 6000) # using the count of the smallest Sentiment category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive              6000\n",
       "Negative              6000\n",
       "Neutral               6000\n",
       "Extremely Negative    6000\n",
       "Extremely Positive    6000\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_balanced[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract info from DATA so we can use it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = DATA_balanced[\"OriginalTweet\"]\n",
    "sentiment = DATA_balanced[\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Hi our farmers are keeping the supermarket she...\n",
       "1    Scammers are using illegal robocalls to pitch ...\n",
       "2    #Coronavirus Ppl are getting into panic buying...\n",
       "3    A man has been accused of exploiting peopleÂ’s...\n",
       "4    Im genuinely worried for the future of our mil...\n",
       "5    This is just one of many videos from my food s...\n",
       "6    One forecast sees Brent crude going as low as ...\n",
       "7    2020 so far\\r\\r\\n?Australian Bush fires\\r\\r\\n?...\n",
       "8    YÂ’all people need to stop panic buying! How m...\n",
       "9    Just dropped my daughter off for a shift at Mc...\n",
       "Name: OriginalTweet, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>67660</td>\n",
       "      <td>Utah</td>\n",
       "      <td>24/03/2020</td>\n",
       "      <td>for Testing for 19 is only conducted in verifi...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2328</th>\n",
       "      <td>71295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25/03/2020</td>\n",
       "      <td>At the next State of the Union address I want ...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21187</th>\n",
       "      <td>69531</td>\n",
       "      <td>NJ, USA</td>\n",
       "      <td>25/03/2020</td>\n",
       "      <td>More online grocery orders More buying in bulk...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20062</th>\n",
       "      <td>57087</td>\n",
       "      <td>Hampshire and Beyond</td>\n",
       "      <td>19/03/2020</td>\n",
       "      <td>Sainsbury's packed with customers for Over 70s...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16996</th>\n",
       "      <td>78072</td>\n",
       "      <td>United States</td>\n",
       "      <td>05/04/2020</td>\n",
       "      <td>Going to the supermarket was so strange. And t...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28626</th>\n",
       "      <td>69024</td>\n",
       "      <td>Worcester, Massachusetts</td>\n",
       "      <td>24/03/2020</td>\n",
       "      <td>You're reading this on Twitter, so we're going...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15682</th>\n",
       "      <td>49617</td>\n",
       "      <td>Sheffield, the North</td>\n",
       "      <td>17/03/2020</td>\n",
       "      <td>A pledge; no supermarket beer until #COVID2019...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290</th>\n",
       "      <td>88867</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13/04/2020</td>\n",
       "      <td>New on the blog....Panic Buying: Combating Foo...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142</th>\n",
       "      <td>77585</td>\n",
       "      <td>Warrenton,  Virginia</td>\n",
       "      <td>05/04/2020</td>\n",
       "      <td>We went for a drive. We are all fucked. Nobody...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11751</th>\n",
       "      <td>61196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21/03/2020</td>\n",
       "      <td>Coronavirus COVID-19: Facebook bans ads on tes...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ScreenName                  Location     TweetAt  \\\n",
       "3981        67660                      Utah  24/03/2020   \n",
       "2328        71295                       NaN  25/03/2020   \n",
       "21187       69531                   NJ, USA  25/03/2020   \n",
       "20062       57087      Hampshire and Beyond  19/03/2020   \n",
       "16996       78072             United States  05/04/2020   \n",
       "...           ...                       ...         ...   \n",
       "28626       69024  Worcester, Massachusetts  24/03/2020   \n",
       "15682       49617      Sheffield, the North  17/03/2020   \n",
       "2290        88867                       NaN  13/04/2020   \n",
       "2142        77585      Warrenton,  Virginia  05/04/2020   \n",
       "11751       61196                       NaN  21/03/2020   \n",
       "\n",
       "                                           OriginalTweet           Sentiment  \n",
       "3981   for Testing for 19 is only conducted in verifi...  Extremely Negative  \n",
       "2328   At the next State of the Union address I want ...  Extremely Negative  \n",
       "21187  More online grocery orders More buying in bulk...             Neutral  \n",
       "20062  Sainsbury's packed with customers for Over 70s...             Neutral  \n",
       "16996  Going to the supermarket was so strange. And t...            Negative  \n",
       "...                                                  ...                 ...  \n",
       "28626  You're reading this on Twitter, so we're going...            Positive  \n",
       "15682  A pledge; no supermarket beer until #COVID2019...            Negative  \n",
       "2290   New on the blog....Panic Buying: Combating Foo...  Extremely Negative  \n",
       "2142   We went for a drive. We are all fucked. Nobody...  Extremely Negative  \n",
       "11751  Coronavirus COVID-19: Facebook bans ads on tes...  Extremely Positive  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_balanced.sample(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tweet,           # texts for the model\n",
    "                                                    sentiment,          # classification labels\n",
    "                                                    test_size=0.2,   # create an 80/20 split\n",
    "                                                    random_state=42) # random state for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Extremely Positive    1244\n",
       "Negative              1216\n",
       "Positive              1190\n",
       "Extremely Negative    1179\n",
       "Neutral               1171\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral               4829\n",
       "Extremely Negative    4821\n",
       "Positive              4810\n",
       "Negative              4784\n",
       "Extremely Positive    4756\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Vectorizing and Feature Extraction__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range = (1,2),     # unigrams and bigrams (1 word and 2 word units)\n",
    "                             lowercase = True,       # why use lowercase?\n",
    "                             max_df = 0.95,           # remove very common words\n",
    "                             min_df = 0.05,           # remove very rare words\n",
    "                             max_features = 1000)      # keep only top 500 features\n",
    "\n",
    "# This vectorizer is then used to turn all of our documents into a vector of numbers, instead of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we do it for our training data...\n",
    "X_train_feats = vectorizer.fit_transform(X_train)\n",
    "#... then we do it for our test data\n",
    "X_test_feats = vectorizer.transform(X_test)\n",
    "# We can also create a list of the feature names. \n",
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 34)\t0.30808155865826475\n",
      "  (0, 13)\t0.307182740641691\n",
      "  (0, 33)\t0.3078486651083938\n",
      "  (0, 60)\t0.6048243429868285\n",
      "  (0, 12)\t0.5917273279037271\n"
     ]
    }
   ],
   "source": [
    "print(X_train_feats[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['19', 'about', 'all', 'amp', 'an', 'and', 'are', 'as', 'at', 'be', 'but', 'by', 'can', 'co', 'consumer', 'coronavirus', 'covid', 'covid 19', 'covid19', 'covid_19', 'do', 'during', 'food', 'for', 'from', 'get', 'go', 'grocery', 'grocery store', 'has', 'have', 'home', 'how', 'https', 'https co', 'if', 'in', 'in the', 'is', 'it', 'just', 'like', 'more', 'my', 'need', 'no', 'not', 'now', 'of', 'of the', 'on', 'online', 'or', 'our', 'out', 'pandemic', 'panic', 'people', 'prices', 'sanitizer', 'shopping', 'so', 'some', 'stock', 'store', 'supermarket', 'that', 'the', 'the coronavirus', 'the grocery', 'their', 'there', 'they', 'this', 'time', 'to', 'to the', 'up', 'us', 'was', 'we', 'what', 'when', 'who', 'will', 'with', 'you', 'your']\n"
     ]
    }
   ],
   "source": [
    "print(feature_names[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = preprocessing.StandardScaler(with_mean=False)\n",
    "X_scaled = sc.fit_transform(X_train_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 34)\t0.30808155865826475\n",
      "  (0, 13)\t0.307182740641691\n",
      "  (0, 33)\t0.3078486651083938\n",
      "  (0, 60)\t0.6048243429868285\n",
      "  (0, 12)\t0.5917273279037271\n",
      "  (1, 76)\t0.27156276327140116\n",
      "  (1, 7)\t0.24558993681778626\n",
      "  (1, 6)\t0.19511260461427565\n",
      "  (1, 66)\t0.23405263431421544\n",
      "  (1, 65)\t0.2211906081309274\n",
      "  (1, 26)\t0.31138847297666156\n",
      "  (1, 75)\t0.3651488888546413\n",
      "  (1, 48)\t0.1525297738013317\n",
      "  (1, 31)\t0.3115114032410228\n",
      "  (1, 23)\t0.1798471518030512\n",
      "  (1, 3)\t0.26273588237999596\n",
      "  (1, 36)\t0.1586504496723947\n",
      "  (1, 67)\t0.235462975895514\n",
      "  (1, 19)\t0.25628222719195326\n",
      "  (1, 24)\t0.2484015493653924\n",
      "  (1, 2)\t0.2533602003520663\n",
      "  (2, 30)\t1.0\n",
      "  (3, 28)\t0.1664308146271363\n",
      "  (3, 15)\t0.10001809443088566\n",
      "  (3, 64)\t0.1487923921669153\n",
      "  :\t:\n",
      "  (23997, 48)\t0.1432851801033097\n",
      "  (23997, 24)\t0.4666926312382781\n",
      "  (23998, 22)\t0.28308760096186847\n",
      "  (23998, 37)\t0.352431148231316\n",
      "  (23998, 40)\t0.3806266675984466\n",
      "  (23998, 56)\t0.3652366406841327\n",
      "  (23998, 17)\t0.23503401326549742\n",
      "  (23998, 0)\t0.2271201072060144\n",
      "  (23998, 16)\t0.23147917984277094\n",
      "  (23998, 50)\t0.26194693966591714\n",
      "  (23998, 23)\t0.22945547323988935\n",
      "  (23998, 36)\t0.2024119572889615\n",
      "  (23998, 67)\t0.30041214455118886\n",
      "  (23998, 2)\t0.3232460680589453\n",
      "  (23999, 82)\t0.4574068606362635\n",
      "  (23999, 10)\t0.19862345370608453\n",
      "  (23999, 83)\t0.2166259220888668\n",
      "  (23999, 54)\t0.5861101268408029\n",
      "  (23999, 15)\t0.10960185537527911\n",
      "  (23999, 76)\t0.19862345370608453\n",
      "  (23999, 65)\t0.16178080523656493\n",
      "  (23999, 26)\t0.45550467377647086\n",
      "  (23999, 75)\t0.08902439660423801\n",
      "  (23999, 67)\t0.172219743711839\n",
      "  (23999, 12)\t0.19537004228026764\n"
     ]
    }
   ],
   "source": [
    "print(X_train_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Classifying and predicting__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cds-au613522/cds-language/my_repo_language_github/LanguageAnalytics/assignment5_SupervisedML/ML_environment/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression(random_state=42).fit(X_train_feats, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = preprocessing.StandardScaler(with_mean=False)\n",
    "X_scaled = sc.fit_transform(X_train_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cds-au613522/cds-language/my_repo_language_github/LanguageAnalytics/assignment5_SupervisedML/ML_environment/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression(random_state=42).fit(X_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_environment",
   "language": "python",
   "name": "ml_environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
